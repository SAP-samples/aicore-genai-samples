{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4d8f0d470dd5ce2",
   "metadata": {},
   "source": [
    "# Orchestration with GenAI Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfa2bb46ec75e47",
   "metadata": {},
   "source": [
    "This notebook demonstrates setting up data masking and content filtering, configuring an orchestration pipeline, and querying multiple LLM models with GenAI Hub."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fc1942",
   "metadata": {},
   "source": [
    "Installing the required packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdccc0b7",
   "metadata": {},
   "source": [
    "The code imports required libraries, reads credentials from a creds.json file, and sets environment variables for authentication and API access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96da5c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://anuragvxxx.authentication.eu10.hana.ondemand.com/oauth/token\n",
      "sb-xxxxxxx\n",
      "10xxxxx=\n",
      "https://api.ai.prod.eu-central-1.aws.ml.hana.ondemand.com/v2\n",
      "grounding\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "import os\n",
    "from IPython.display import clear_output\n",
    "from ai_core_sdk.ai_core_v2_client import AICoreV2Client\n",
    "from ai_api_client_sdk.models.parameter_binding import ParameterBinding\n",
    "from enum import Enum\n",
    " \n",
    "# Inline credentials\n",
    "with open('creds.json') as f:\n",
    "    credCF = json.load(f)\n",
    "\n",
    "# Set environment variables\n",
    "def set_environment_vars(credCF):\n",
    "    env_vars = {\n",
    "        'AICORE_AUTH_URL': credCF['url'] + '/oauth/token',\n",
    "        'AICORE_CLIENT_ID': credCF['clientid'],\n",
    "        'AICORE_CLIENT_SECRET': credCF['clientsecret'],\n",
    "        'AICORE_BASE_URL': credCF[\"serviceurls\"][\"AI_API_URL\"] + \"/v2\",\n",
    "        'AICORE_RESOURCE_GROUP': \"grounding\" \n",
    "    }\n",
    "\n",
    "    for key, value in env_vars.items():\n",
    "        os.environ[key] = value\n",
    "        print(value)\n",
    "\n",
    "# Create AI Core client instance\n",
    "def create_ai_core_client(credCF):\n",
    "    set_environment_vars(credCF)  # Ensure environment variables are set\n",
    "    return AICoreV2Client(\n",
    "        base_url=os.environ['AICORE_BASE_URL'],\n",
    "        auth_url=os.environ['AICORE_AUTH_URL'],\n",
    "        client_id=os.environ['AICORE_CLIENT_ID'],\n",
    "        client_secret=os.environ['AICORE_CLIENT_SECRET'],\n",
    "        resource_group=os.environ['AICORE_RESOURCE_GROUP']\n",
    "    )\n",
    "\n",
    "ai_core_client = create_ai_core_client(credCF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79167b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "YOUR_API_URL = \"https://api.ai.prodeuonly.eu-central-1.aws.ml.hana.ondemand.com/v2/inference/deployments/db4b41879faa1ed4\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc8ab8b",
   "metadata": {},
   "source": [
    "## Basic Orchestration Pipeline\n",
    "\n",
    "Now that you have YOUR_DEPOLYMENT_URL, let's walk through a basic orchestration pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be250e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Subject: Bestellung #1234567890 VerspÃ¤tet - John Johnson Nachricht: Halle, ich schreibe ihnen um mich nach dem Status meiner Bestellung mit der Bestellnr. +1234567890 zu erkundigen. Die Lieferung war eigentlich fÃ¼r gestern geplant, ist bisher jedoch nicht erfolgt. Mein Name ist John Johnson und meine Lieferadresse lautet 125 Cole Meadows Drive Palo Alto, California 94301. Bitte lassen Sie mich per Telefon unter der Nummer +1 505802 2172 wissen, wann ich mit meiner Lieferung rechnen kann. Danke!\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from gen_ai_hub.orchestration.utils import load_text_file \n",
    "# Load the support request file content \n",
    "support_request_path = r\"C:\\Users\\C5384965\\OneDrive - SAP SE\\2026\\jan-26\\06-01-26\\ai-core-orchestration-consumption-opt\\support-request.txt\" # Specify the correct path to the file \n",
    "support_request = load_text_file(support_request_path) \n",
    "# Print the content to verify it has been loaded \n",
    "print(support_request)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dac7637",
   "metadata": {},
   "source": [
    "# Step 1: Templating\n",
    "\n",
    "Explanation of Templating Code\n",
    "\n",
    "This code defines a template for an AI assistant using orchestration configuration. The `Template` object is set up with system and user messages to guide the assistant’s response behavior. \n",
    "\n",
    "Key Components:\n",
    "- **SystemMessage**: Sets a predefined instruction for the AI assistant. This message typically includes the assistant's role and any specific guidelines it should follow.\n",
    "- **UserMessage**: Represents the user's input and how it is structured in the conversation.\n",
    "  \n",
    "In this revised prompt, only queries are passed to the assistant without any additional context. The AI is expected to respond based solely on the provided input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ff397f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration.models.message import SystemMessage, UserMessage\n",
    "from gen_ai_hub.orchestration.models.template import Template, TemplateValue\n",
    "\n",
    "# Define the sentiment analysis template\n",
    "template = Template(\n",
    "    messages=[\n",
    "        SystemMessage(\n",
    "            \"\"\"You are a customer support assistant. Analyze the sentiment of the user request provided and return whether the sentiment is positive, neutral, or negative. Also provide a one-line justification for your classification.\"\"\"\n",
    "        ),\n",
    "        UserMessage(\n",
    "            \"Please analyze the sentiment of the following support request: {{?support_text}}\"\n",
    "        ),\n",
    "    ],\n",
    "    defaults=[\n",
    "        TemplateValue(name=\"support_text\", value=\"User is unhappy with the latest update and facing usability issues.\"),\n",
    "    ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe251e0",
   "metadata": {},
   "source": [
    "# Step 2: Define the LLM -list of models\n",
    "\n",
    "The LLM class is used to configure and initialize a model for generating text based on specific parameters. In this example, we'll use the list of models to perform the content creation task.\n",
    "\n",
    "ℹ️Note that virtual deployment of the model is managed automatically by the Orchestration Service, so no additional deployment setup is required on your part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62d96bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration.models.llm import LLM\n",
    "\n",
    "llm = LLM(name=\"gpt-5-nano\", parameters={\"max_completion_tokens\": 512})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e8a4ae",
   "metadata": {},
   "source": [
    "This configuration initializes the model to use the list of llm models with the latest updates. The model will generate responses up to 256 tokens in length and produce more predictable and focused output due to the low temperature setting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfeeca7",
   "metadata": {},
   "source": [
    "### Data Masking\n",
    "\n",
    "The Data Masking Module anonymizes or pseudonymizes personally identifiable information (PII) before it is processed by the LLM module. When data is anonymized, all identifying information is replaced with placeholders (e.g., MASKED_ENTITY), and the original data cannot be recovered, ensuring that no trace of the original information is retained. In contrast, pseudonymized data is substituted with unique placeholders (e.g., MASKED_ENTITY_ID), allowing the original information to be restored if needed. In both cases, the masking module identifies sensitive data and replaces it with appropriate placeholders before further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3af1194a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration.models.data_masking import DataMasking\n",
    "from gen_ai_hub.orchestration.models.sap_data_privacy_integration import SAPDataPrivacyIntegration, MaskingMethod, ProfileEntity\n",
    "\n",
    "# Apply data masking to sensitive information in the resume\n",
    "data_masking = DataMasking(\n",
    "    providers=[\n",
    "        SAPDataPrivacyIntegration(\n",
    "            method=MaskingMethod.ANONYMIZATION,  # or MaskingMethod.PSEUDONYMIZATION\n",
    "            entities=[\n",
    "                ProfileEntity.EMAIL,\n",
    "                ProfileEntity.PHONE,\n",
    "                ProfileEntity.PERSON,\n",
    "                ProfileEntity.ORG,\n",
    "                ProfileEntity.LOCATION\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1490f85f",
   "metadata": {},
   "source": [
    "### Content Filtering\n",
    "\n",
    "The Content Filtering Module can be configured to filter both the input to the LLM module (input filter) and the output generated by the LLM (output filter). The module uses predefined classification services to detect inappropriate or unwanted content, allowing flexible configuration through customizable thresholds. These thresholds can be set to control the sensitivity of filtering, ensuring that content meets desired standards before it is processed or returned as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "befd5ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from gen_ai_hub.orchestration.models.azure_content_filter import AzureContentFilter, AzureThreshold\n",
    "from gen_ai_hub.orchestration.models.llama_guard_3_filter import LlamaGuard38bFilter\n",
    "\n",
    "input_filter= AzureContentFilter(hate=AzureThreshold.ALLOW_SAFE,\n",
    "                                  violence=AzureThreshold.ALLOW_SAFE,\n",
    "                                  self_harm=AzureThreshold.ALLOW_SAFE,\n",
    "                                  sexual=AzureThreshold.ALLOW_SAFE)\n",
    "input_filter_llama = LlamaGuard38bFilter(hate=True)\n",
    "output_filter = AzureContentFilter(hate=AzureThreshold.ALLOW_SAFE,\n",
    "                                   violence=AzureThreshold.ALLOW_SAFE_LOW,\n",
    "                                   self_harm=AzureThreshold.ALLOW_SAFE_LOW_MEDIUM,\n",
    "                                   sexual=AzureThreshold.ALLOW_ALL)\n",
    "output_filter_llama = LlamaGuard38bFilter(hate=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1199e6",
   "metadata": {},
   "source": [
    "### Translation\n",
    "\n",
    "Translation module can be used to translate text from one language to another. You can use this module to translate input text before it is processed by the LLM module, or to translate the output generated by the LLM module. The translation module uses the SAP Document Translation service to perform the translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe2dc609",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration.models.translation.translation import InputTranslationConfig, OutputTranslationConfig\n",
    "from gen_ai_hub.orchestration.models.translation.sap_document_translation import SAPDocumentTranslation\n",
    "\n",
    "input_config = InputTranslationConfig(source_language=\"de-DE\", target_language=\"en-US\")\n",
    "output_config = OutputTranslationConfig(source_language=\"en-US\", target_language=\"de-DE\")\n",
    "\n",
    "translation_module = SAPDocumentTranslation(\n",
    "    input_translation_config=input_config,\n",
    "    output_translation_config=output_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c270b13d",
   "metadata": {},
   "source": [
    "# Step 3: Create the Orchestration Configuration\n",
    "\n",
    "The OrchestrationConfig class is used to create a configuration that integrates various components, such as templates and llm models, into a unified orchestration setup. This configuration specifies how these components work together to achieve the desired workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514b1d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration.models.config import OrchestrationConfig\n",
    "from gen_ai_hub.orchestration.models.content_filtering import InputFiltering, OutputFiltering, ContentFiltering\n",
    "# Define content filtering\n",
    "content_filtering = ContentFiltering(\n",
    "    input_filtering=InputFiltering(filters=[input_filter, input_filter_llama]),\n",
    "    output_filtering=OutputFiltering(filters=[output_filter, output_filter_llama]),\n",
    ")\n",
    "\n",
    "config = OrchestrationConfig(\n",
    "    template=template,\n",
    "    llm=llm,  \n",
    "    filtering=content_filtering, \n",
    "    data_masking = data_masking,\n",
    "    translation=translation_module \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd79ec07",
   "metadata": {},
   "source": [
    "# Step 4: Run the Orchestration Request\n",
    "\n",
    "The OrchestrationService class is used to interact with the orchestration service by providing a configuration and invoking its operations. This service handles the execution of workflows defined by the provided configuration and processes inputs accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e9ac4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration.service import OrchestrationService\n",
    "\n",
    "orchestration_service = OrchestrationService()\n",
    "\n",
    "# Run orchestration with the provided input (for example, candidate resume content)\n",
    "result = orchestration_service.run(config=config, template_values=[\n",
    "        TemplateValue(name=\"support_text\", value=support_request)  \n",
    "    ])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e8c093da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negativ – Die Nachricht drückt Frustration und Dringlichkeit aufgrund einer verspäteten Lieferung aus und fordert eine zeitnahe Nachverfolgung an.\n"
     ]
    }
   ],
   "source": [
    "# Extract the response content\n",
    "response = result.orchestration_result.choices[0].message.content\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7014f9",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
