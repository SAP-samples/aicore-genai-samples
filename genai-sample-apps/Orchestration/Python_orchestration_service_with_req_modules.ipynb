{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4d8f0d470dd5ce2",
   "metadata": {},
   "source": [
    "# Orchestration with GenAI Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfa2bb46ec75e47",
   "metadata": {},
   "source": [
    "This notebook demonstrates, configuring an orchestration pipeline, and querying multiple LLM models with GenAI Hub."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdccc0b7",
   "metadata": {},
   "source": [
    "The code imports required libraries, reads credentials from a creds.json file, and sets environment variables for authentication and API access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96da5c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://anuragv2-39wjy902.authentication.eu10.hana.ondemand.com/oauth/token\n",
      "sb-adcd4907-f1a7-462d-ba8e-646390ee4185!b398425|aicore!b540\n",
      "107d3e9b-9a41-4b30-9b24-a091a45956cd$VmYxjzammFm50xkj1O37HmzgX3maoNrwfrlm99qUhi0=\n",
      "https://api.ai.prod.eu-central-1.aws.ml.hana.ondemand.com/v2\n",
      "grounding\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "import os\n",
    "from IPython.display import clear_output\n",
    "from ai_core_sdk.ai_core_v2_client import AICoreV2Client\n",
    " \n",
    "# Inline credentials\n",
    "with open('creds.json') as f:\n",
    "    credCF = json.load(f)\n",
    "\n",
    "# Set environment variables\n",
    "def set_environment_vars(credCF):\n",
    "    env_vars = {\n",
    "        'AICORE_AUTH_URL': credCF['url'] + '/oauth/token',\n",
    "        'AICORE_CLIENT_ID': credCF['clientid'],\n",
    "        'AICORE_CLIENT_SECRET': credCF['clientsecret'],\n",
    "        'AICORE_BASE_URL': credCF[\"serviceurls\"][\"AI_API_URL\"] + \"/v2\",\n",
    "        'AICORE_RESOURCE_GROUP': \"grounding\" \n",
    "    }\n",
    "\n",
    "    for key, value in env_vars.items():\n",
    "        os.environ[key] = value\n",
    "        print(value)\n",
    "\n",
    "# Create AI Core client instance\n",
    "def create_ai_core_client(credCF):\n",
    "    set_environment_vars(credCF)  # Ensure environment variables are set\n",
    "    return AICoreV2Client(\n",
    "        base_url=os.environ['AICORE_BASE_URL'],\n",
    "        auth_url=os.environ['AICORE_AUTH_URL'],\n",
    "        client_id=os.environ['AICORE_CLIENT_ID'],\n",
    "        client_secret=os.environ['AICORE_CLIENT_SECRET'],\n",
    "        resource_group=os.environ['AICORE_RESOURCE_GROUP']\n",
    "    )\n",
    "\n",
    "ai_core_client = create_ai_core_client(credCF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c03e8b",
   "metadata": {},
   "source": [
    "### Create a New Orchestration Configuration\n",
    "In this step, a new configuration is created using the ai_core_client. It involves defining identifiers like scenario_id, executable_id, and a configuration name. This configuration is essential for setting up the orchestration workflow.\n",
    "\n",
    "Key Points:\n",
    "\n",
    "Scenario ID: Specifies the context of the orchestration scenario.\n",
    "\n",
    "Executable ID: Identifies the executable to be used in orchestration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86eecdbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: sap-ai-sdk-gen\n",
      "Version: 5.10.0\n",
      "Summary: SAP Cloud SDK for AI (Python): generative AI SDK\n",
      "Home-page: https://www.sap.com/\n",
      "Author: SAP SE\n",
      "Author-email: \n",
      "License: SAP DEVELOPER LICENSE AGREEMENT\n",
      "Location: C:\\Users\\C5384965\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\n",
      "Requires: click, dacite, h11, httpx, langchain, langchain-community, langchain-openai, openai, overloading, packaging, pydantic, sap-ai-sdk-core\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show sap-ai-sdk-gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30b6253a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration created successfully with ID: b9a2523c-8117-401e-afad-c57463bdb28b and Name: config-new-orchestration\n"
     ]
    }
   ],
   "source": [
    "# Define scenario ID, executable ID, and configuration suffix\n",
    "scenario_id = \"orchestration\"\n",
    "executable_id = \"orchestration\"\n",
    "config_suffix = \"config-new\"\n",
    "config_name = f\"{config_suffix}-orchestration\"\n",
    "\n",
    "# Create a new configuration\n",
    "config = ai_core_client.configuration.create(\n",
    "    scenario_id=scenario_id,\n",
    "    executable_id=executable_id,\n",
    "    name=config_name\n",
    ")\n",
    "\n",
    "print(f\"Configuration created successfully with ID: {config.id} and Name: {config_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f60625",
   "metadata": {},
   "source": [
    "### Create and Monitor the Deployment\n",
    "This step involves creating a deployment using the previously created configuration ID and monitoring the deployment status until it becomes ready. The deployment is created via the ai_core_client, and a helper function (spinner) is used to check the status periodically.\n",
    "\n",
    "Key Points:\n",
    "\n",
    "Deployment Creation: Uses the configuration ID to create a new deployment.\n",
    "\n",
    "Status Check: Utilizes a callback function to check if the deployment is in a 'RUNNING' state.\n",
    "\n",
    "Spinner Function: Provides a visual indication while waiting for the deployment to be ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3aa06ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deployment created successfully with ID: d44f35f25720493c\n"
     ]
    }
   ],
   "source": [
    "# Create a deployment using the configuration ID from the previous cell\n",
    "deployment = ai_core_client.deployment.create(configuration_id=config.id)\n",
    "\n",
    "print(f\"Deployment created successfully with ID: {deployment.id}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08922c5",
   "metadata": {},
   "source": [
    "### Monitoring the Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32181da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for the deployment to become ready... \\\n",
      "Deployment is ready with status: Status.RUNNING\n"
     ]
    }
   ],
   "source": [
    "from ai_api_client_sdk.models.status import Status\n",
    "\n",
    "def spinner(check_callback, timeout=300, check_every_n_seconds=10):\n",
    "    start = time.time()\n",
    "    while time.time() - start < timeout:\n",
    "        return_value = check_callback()\n",
    "        if return_value:\n",
    "            return return_value\n",
    "        for char in '|/-\\\\':\n",
    "            clear_output(wait=True)\n",
    "            print(f'Waiting for the deployment to become ready... {char}')\n",
    "            time.sleep(0.2)\n",
    "\n",
    "# Define the callback to check if the deployment is ready\n",
    "def check_ready():\n",
    "    updated_deployment = ai_core_client.deployment.get(deployment.id)\n",
    "    return updated_deployment if updated_deployment.status == Status.RUNNING else None\n",
    "\n",
    "# Wait for the deployment to be ready\n",
    "ready_deployment = spinner(check_ready)\n",
    "print(f\"Deployment is ready with status: {ready_deployment.status}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc8ab8b",
   "metadata": {},
   "source": [
    "## Basic Orchestration Pipeline\n",
    "\n",
    "Now that you have YOUR_DEPOLYMENT_URL, let's walk through a basic orchestration pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8a2a07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John Doe\n",
      "1234 Data St, San Francisco, CA 94101\n",
      "(123) 456-7890\n",
      "johndoe@email.com\n",
      "LinkedIn Profile\n",
      "GitHub Profile\n",
      "\n",
      "Objective\n",
      "Detail-oriented Data Scientist with 3+ years of experience in data analysis, statistical modeling, and machine learning. Seeking to leverage expertise in predictive modeling and data visualization to help drive data-informed decision-making at [Company Name].\n",
      "\n",
      "Education\n",
      "Master of Science in Data Science\n",
      "University of California, Berkeley\n",
      "Graduated: May 2021\n",
      "\n",
      "Bachelor of Science in Computer Science\n",
      "University of California, Los Angeles\n",
      "Graduated: May 2019\n",
      "\n",
      "Technical Skills\n",
      "\n",
      "Programming Languages: Python, R, SQL, Java\n",
      "Data Analysis & Visualization: Pandas, NumPy, Matplotlib, Seaborn, Tableau\n",
      "Machine Learning: Scikit-learn, TensorFlow, Keras, XGBoost\n",
      "Big Data Technologies: Hadoop, Spark\n",
      "Databases: MySQL, PostgreSQL\n",
      "Version Control: Git\n",
      "\n",
      "Professional Experience\n",
      "\n",
      "Data Scientist\n",
      "DataCorp Inc., San Francisco, CA\n",
      "June 2021 – Present\n",
      "\n",
      "Developed predictive models to optimize marketing campaigns, which increased ROI by 20%.\n",
      "Conducted in-depth data analysis using Python and SQL to identify trends and patterns in large datasets.\n",
      "Collaborated with cross-functional teams to implement data-driven strategies that improved customer satisfaction scores by 15%.\n",
      "Created interactive dashboards using Tableau to visualize KPIs for stakeholders.\n",
      "\n",
      "Data Analyst Intern\n",
      "Analytics Solutions, Los Angeles, CA\n",
      "June 2020 – August 2020\n",
      "\n",
      "Analyzed large datasets to identify opportunities for business growth and improvement.\n",
      "Assisted in the development of automated reporting tools using Python and Excel.\n",
      "Worked with data visualization tools to create insightful reports for management.\n",
      "\n",
      "Projects\n",
      "\n",
      "Customer Segmentation Analysis\n",
      "Conducted K-means clustering on customer data to segment the customer base into distinct groups, enabling targeted marketing strategies.\n",
      "\n",
      "Predictive Stock Price Modeling\n",
      "Built a predictive model using time series analysis to forecast stock prices, achieving an accuracy rate of 85%.\n",
      "\n",
      "Sentiment Analysis on Social Media\n",
      "Implemented natural language processing techniques to analyze sentiment from tweets, providing insights into public opinion on various topics.\n",
      "\n",
      "Certifications\n",
      "\n",
      "Certified Data Scientist (CDS) – Data Science Council of America\n",
      "Machine Learning Specialization – Coursera by Stanford University\n",
      "\n",
      "Professional Affiliations\n",
      "\n",
      "Member, Association for Computing Machinery (ACM)\n",
      "Member, Data Science Society\n",
      "\n",
      "References\n",
      "Available upon request.\n",
      "\n",
      "Personal Interests\n",
      "- I absolutely love exploring new technologies and working on innovative projects.\n",
      "- I enjoy reading books, especially on artificial intelligence and machine learning.\n",
      "- I hate people who are dishonest and unreliable.\n",
      "- I love traveling and experiencing new cultures.\n",
      "- I enjoy playing video games, especially competitive ones.\n",
      "- I hate being stuck in a routine; I always seek new challenges and growth opportunities.\n",
      "-I hate working in Azure cloud -\"Azure cloud is the most irritating platform i have ever used\"\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\c'\n",
      "C:\\Users\\C5384965\\AppData\\Local\\Temp\\ipykernel_18740\\1292149158.py:4: SyntaxWarning: invalid escape sequence '\\c'\n",
      "  cv_file_path = \"img\\cv.txt\"  # Specify the correct path to the CV file\n"
     ]
    }
   ],
   "source": [
    "from gen_ai_hub.orchestration.utils import load_text_file\n",
    "\n",
    "# Load the CV file content\n",
    "cv_file_path = \"img\\cv.txt\"  # Specify the correct path to the CV file\n",
    "cv_content = load_text_file(cv_file_path)\n",
    "\n",
    "# Print the content to verify it has been loaded\n",
    "print(cv_content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dac7637",
   "metadata": {},
   "source": [
    "# Step 1: Templating\n",
    "\n",
    "Explanation of Templating Code\n",
    "\n",
    "This code defines a template for an AI assistant using orchestration configuration. The `Template` object is set up with system and user messages to guide the assistant’s response behavior. \n",
    "\n",
    "Key Components:\n",
    "- **SystemMessage**: Sets a predefined instruction for the AI assistant. This message typically includes the assistant's role and any specific guidelines it should follow.\n",
    "- **UserMessage**: Represents the user's input and how it is structured in the conversation.\n",
    "  \n",
    "In this revised prompt, only queries are passed to the assistant without any additional context. The AI is expected to respond based solely on the provided input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1427a640",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration.models.message import SystemMessage, UserMessage\n",
    "from gen_ai_hub.orchestration.models.template import Template, TemplateValue\n",
    "\n",
    "# Define the template for resume screening\n",
    "template = Template(\n",
    "    messages=[\n",
    "        SystemMessage(\"\"\"You are a helpful AI assistant for HR. Summarize the following CV in 10 sentences, \n",
    "                      focusing on key qualifications, work experience, and achievements. Include personal contact information, \n",
    "                      organizational history, and personal interests\"\"\"),\n",
    "        UserMessage(\n",
    "            \"Here is a candidate's resume: {{?candidate_resume}}\"\n",
    "        ),\n",
    "    ],\n",
    "    defaults=[\n",
    "        TemplateValue(name=\"candidate_resume\", value=\"John Doe's resume content goes here...\"),\n",
    "    ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe251e0",
   "metadata": {},
   "source": [
    "# Step 2: Define the LLM \n",
    "\n",
    "The LLM class is used to configure and initialize a model for generating text based on specific parameters. In this example, we'll use the gpt-4o model to perform the content creation task.\n",
    "\n",
    "ℹ️Note that virtual deployment of the model is managed automatically by the Orchestration Service, so no additional deployment setup is required on your part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2850b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration.models.llm import LLM\n",
    "model = LLM(\n",
    "    name=\"gpt-4o\",\n",
    "    version=\"latest\",\n",
    "    parameters={\"max_tokens\": 1000, \"temperature\": 0.6},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e8a4ae",
   "metadata": {},
   "source": [
    "This configuration initializes the model to use the llm models with the latest updates. The model will generate responses up to 256 tokens in length and produce more predictable and focused output due to the low temperature setting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c270b13d",
   "metadata": {},
   "source": [
    "# Step 3: Create the Orchestration Configuration\n",
    "\n",
    "The OrchestrationConfig class is used to create a configuration that integrates various components, such as templates and llm models, into a unified orchestration setup. This configuration specifies how these components work together to achieve the desired workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc161825",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from gen_ai_hub.orchestration.models.config import OrchestrationConfig\n",
    "\n",
    "config = OrchestrationConfig(\n",
    "    template=template,   \n",
    "    llm=model,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd79ec07",
   "metadata": {},
   "source": [
    "# Step 4: Run the Orchestration Request\n",
    "\n",
    "The OrchestrationService class is used to interact with the orchestration service by providing a configuration and invoking its operations. This service handles the execution of workflows defined by the provided configuration and processes inputs accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6102ba20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Response from gpt-4o ===\n",
      "John Doe is a detail-oriented Data Scientist with over three years of experience in data analysis, statistical modeling, and machine learning. He holds a Master of Science in Data Science from the University of California, Berkeley, and a Bachelor of Science in Computer Science from UCLA. John is proficient in several programming languages including Python, R, SQL, and Java, and is skilled in data analysis and visualization tools such as Pandas, NumPy, and Tableau. His expertise extends to machine learning frameworks like Scikit-learn and TensorFlow, as well as big data technologies such as Hadoop and Spark.\n",
      "\n",
      "Currently employed at DataCorp Inc. in San Francisco, John has successfully developed predictive models that optimized marketing campaigns, increasing ROI by 20%, and collaborated on strategies that improved customer satisfaction by 15%. His previous role as a Data Analyst Intern at Analytics Solutions involved analyzing large datasets and building automated reporting tools. He has completed significant projects such as customer segmentation analysis and predictive stock price modeling, achieving an 85% accuracy rate.\n",
      "\n",
      "John is certified by the Data Science Council of America and has completed a Machine Learning Specialization from Coursera. He is an active member of the Association for Computing Machinery and the Data Science Society. John's personal interests include exploring new technologies, reading about artificial intelligence, traveling, and playing competitive video games. He expresses a strong distaste for dishonesty, routine, and working with Azure cloud, which he finds irritating. John's contact information includes a San Francisco address, a phone number, and an email, and he maintains a LinkedIn and GitHub profile for professional networking.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "from gen_ai_hub.orchestration.service import OrchestrationService\n",
    "\n",
    "orchestration_service = OrchestrationService(\n",
    "    api_url=ready_deployment.deployment_url,\n",
    "    config=config\n",
    ")\n",
    "\n",
    "result = orchestration_service.run(\n",
    "    template_values=[TemplateValue(name=\"candidate_resume\", value=cv_content)]\n",
    ")\n",
    "\n",
    "response_text = result.orchestration_result.choices[0].message.content\n",
    "\n",
    "print(\"\\n=== Response from gpt-4o ===\")\n",
    "print(response_text)\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
