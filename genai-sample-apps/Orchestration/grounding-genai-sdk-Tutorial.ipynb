{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leverage Document Grounding in Orchestration Service for RAG-based Content Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this learning journey, you will learn how to leverage the Document Grounding module in the Orchestration Service to generate content using the Retrieval-Augmented Generation (RAG) approach.\n",
    "The Document Grounding module helps in grounding the input questions to relevant documents.\n",
    "The grounding process involves retrieving relevant documents from a knowledge base and using them to high-quality generate responses.\n",
    "The knowledge base can be a collection of documents in a sharepoint folder, aws s3, an elastic search engine, or data repository which contains vectors.\n",
    "\n",
    "In this learning journey, you will perform the following steps:\n",
    "- Create the knowledge base with the relevant documents.\n",
    "- Configure the Document Grounding module in the Orchestration Service.\n",
    "- Generate content based on the knowledge base using the RAG approach.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "Install the Generative AI Hub SDK using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install \"sap-ai-sdk-gen[all]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authenticating AI Core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os \n",
    "from ai_core_sdk.ai_core_v2_client import AICoreV2Client\n",
    "# Inline credentials\n",
    "with open('key.json') as f:\n",
    "    credCF = json.load(f)\n",
    "\n",
    "# Set environment variables\n",
    "def set_environment_vars(credCF):\n",
    "    env_vars = {\n",
    "        'AICORE_AUTH_URL': credCF['url'] + '/oauth/token',\n",
    "        'AICORE_CLIENT_ID': credCF['clientid'],\n",
    "        'AICORE_CLIENT_SECRET': credCF['clientsecret'],\n",
    "        'AICORE_BASE_URL': credCF[\"serviceurls\"][\"AI_API_URL\"] + \"/v2\",\n",
    "        'AICORE_RESOURCE_GROUP': \"grounding\" \n",
    "    }\n",
    "\n",
    "    for key, value in env_vars.items():\n",
    "        os.environ[key] = value\n",
    "        print(value)\n",
    "\n",
    "# Create AI Core client instance\n",
    "def create_ai_core_client(credCF):\n",
    "    set_environment_vars(credCF)  # Ensure environment variables are set\n",
    "    return AICoreV2Client(\n",
    "        base_url=os.environ['AICORE_BASE_URL'],\n",
    "        auth_url=os.environ['AICORE_AUTH_URL'],\n",
    "        client_id=os.environ['AICORE_CLIENT_ID'],\n",
    "        client_secret=os.environ['AICORE_CLIENT_SECRET'],\n",
    "        resource_group=os.environ['AICORE_RESOURCE_GROUP']\n",
    "    )\n",
    "\n",
    "ai_core_client = create_ai_core_client(credCF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the AI Core service key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = json.load(open('key.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "AI_API_URL= key['serviceurls']['AI_API_URL']\n",
    "clientid= key['clientid']\n",
    "clientsecret= key['clientsecret']\n",
    "url= key['url']\n",
    "resource_group = \"grounding\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch Token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step is used to fetch an access token from the SAP AI Core OAuth server using client credentials grant type. The token will be used to authenticate API requests to AI Core (e.g., for creating secrets, executing workflows)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "headers = {\n",
    "    'Content-Type': 'application/x-www-form-urlencoded',\n",
    "    'content-type': 'application/x-www-form-urlencoded',\n",
    "}\n",
    "\n",
    "data = f'grant_type=client_credentials&client_id={clientid}&client_secret={clientsecret}'\n",
    "\n",
    "response = requests.post(f'{url}/oauth/token', headers=headers, data=data)\n",
    "\n",
    "token = response.json()['access_token']\n",
    "\n",
    "print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resource Group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step creates a new resource group in SAP AI Core and tags it with a label (document-grounding) to logically group related resources. The access token is used for authorized API access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'Authorization': f'Bearer {token}',\n",
    "}\n",
    "\n",
    "json_data = {\n",
    "    'resourceGroupId': resource_group,\n",
    "    'labels': [\n",
    "        {\n",
    "            'key': 'ext.ai.sap.com/document-grounding',\n",
    "            'value': 'true',\n",
    "        },\n",
    "    ],\n",
    "}\n",
    "\n",
    "resource = requests.post(f'{AI_API_URL}/v2/admin/resourceGroups', headers=headers, json=json_data)\n",
    "\n",
    "resource.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### configuration and Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step creates a configuration for an LLM orchestration scenario in SAP AI Core using the given executableId and scenarioId. The loop ensures the config is retried until it successfully returns a 201 Created status, handling transient errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'AI-Resource-Group': resource.json()['resourceGroupId'],\n",
    "    'Authorization': f'Bearer {token}',\n",
    "    \"content-type\": \"application/json\"\n",
    "}\n",
    "\n",
    "json_data = {\n",
    "    'name': 'orchestration-config',\n",
    "    'executableId': 'orchestration',\n",
    "    'scenarioId': 'orchestration',\n",
    "}\n",
    "\n",
    "while True:\n",
    "    configuration = requests.post(f'{AI_API_URL}/v2/lm/configurations', headers=headers, json=json_data)\n",
    "    if(configuration.status_code == 201):\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step deploys the LLM configuration. It then waits until the deployment is ready and retrieves the deploymentUrl(orchestration url), which is used to trigger orchestration requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = {\n",
    "    'ttl': '24H',\n",
    "    'configurationId': configuration.json()['id'],\n",
    "}\n",
    "\n",
    "response = requests.post(f'{AI_API_URL}/v2/lm/deployments', headers=headers, json=json_data)\n",
    "\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    deployment = requests.get(f'{AI_API_URL}/v2/lm/deployments', headers=headers) \n",
    "    if(deployment.json()['resources'][0]['deploymentUrl'] != ''):\n",
    "        break\n",
    "\n",
    "deploymentUrl = deployment.json()['resources'][0]['deploymentUrl']\n",
    "\n",
    "deploymentUrl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, you are explicitly defining the orchestration service deployment URL (orchestration_service_url) which points to your deployed LLM configuration. This URL is used to send inference requests (like prompt executions) to the SAP AI Core Orchestration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orchestration_service_url=\"https://api.ai.********************ondemand.com/v2/inference/deployments/dd525568f5e\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generic Secret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this tutorial, we're demonstrating how to create a vector knowledge base by connecting either SharePoint or AWS S3 as the document source‚Äîmultiple options are supported and optional based on your setup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### creating knowledge base using Sharepoint - option 1\n",
    "\n",
    "This step specifically creates a secret in SAP AI Core that stores Base64-encoded credentials for SharePoint access, securely enabling document grounding workflows via Microsoft Graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = {\n",
    "    'name': '<generic secret name>',\n",
    "    'data': {\n",
    "        'description': '<description of generic secret>',\n",
    "        'clientId': '<client id>',\n",
    "        'authentication': 'T0F1dGgyUGFzc3dvcmQ=',\n",
    "        'tokenServiceURL': '<token service url>',\n",
    "        'password': '<password>',\n",
    "        'url': 'aHR0cHM6Ly9ncmFwaC5taWNyb3NvZnQuY29t',\n",
    "        'tokenServiceURLType': 'RGVkaWNhdGVk',\n",
    "        'user': '<user>',\n",
    "        'clientSecret': '<client secret>',\n",
    "        'scope': 'aHR0cHM6Ly9ncmFwaC5taWNyb3NvZnQuY29tLy5kZWZhdWx0',\n",
    "    },\n",
    "    'labels': [\n",
    "        {\n",
    "            'key': 'ext.ai.sap.com/document-grounding',\n",
    "            'value': 'true',\n",
    "        },\n",
    "    ],\n",
    "}\n",
    "\n",
    "secret = requests.post(f'{AI_API_URL}/v2/admin/secrets', headers=headers, json=json_data)\n",
    "\n",
    "secret.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### creating knowledge base using AWS S3 - Option 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, instead of SharePoint, we can use AWS S3 as a document repository for grounding. In the example below, we securely store credentials as a secret named aws-s3-secret that will later be referenced in the pipeline creation.\n",
    "\n",
    "This makes it clear that both SharePoint and AWS S3 are optional approaches and interchangeable based on the user‚Äôs infrastructure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prepare secret payload\n",
    "secret_payload = {\n",
    "    \"name\": \"<generic secret name>\",\n",
    "    \"data\": {  \n",
    "        \"description\": \"<description of generic secret>\",\n",
    "        \"url\": \"<url>\",\n",
    "        \"authentication\": \"Tm9BdXRoZW50aWNhdGlvbg==\",\n",
    "        \"access_key_id\": \"<access key id>\",\n",
    "        \"secret_access_key\": \"<secret access key>\",\n",
    "        \"bucket\": \"<bucket>\",\n",
    "        \"region\": \"<region>\",\n",
    "        \"host\": \"<host>\",\n",
    "        \"username\": \"<username>\"\n",
    "    },\n",
    "    \"labels\": [\n",
    "        {\n",
    "            \"key\": \"ext.ai.sap.com/document-grounding\",\n",
    "            \"value\": \"true\"\n",
    "        },\n",
    "         {\n",
    "            \"key\": \"ext.ai.sap.com/documentRepositoryType\",\n",
    "            \"value\": \"S3\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create secret\n",
    "response = requests.post(f\"{AI_API_URL}/v2/admin/secrets\", headers=headers, json=secret_payload)\n",
    "print(\"Secret creation:\", response.status_code, response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline creation using sharepoint - option 1\n",
    "In this step, we are creating a document grounding pipeline using SharePoint as the knowledge source. The pipeline connects to the document repository defined in the SharePoint site using the previously created secret "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = {\n",
    "    'type': 'MSSharePoint',\n",
    "    'configuration': {\n",
    "        'destination': '<generic secret name>',\n",
    "        'sharePoint': {\n",
    "            'site': {\n",
    "                'name': 'Dev_blr3_document',\n",
    "                \"includePaths\": [\n",
    "          \"/sample_emails/output_texts\"\n",
    "        ]\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "while True:\n",
    "    pipeline = requests.post(f'{AI_API_URL}/v2/lm/document-grounding/pipelines', headers=headers, json=json_data)\n",
    "    if(pipeline.status_code == 201):\n",
    "        break\n",
    "\n",
    "pipeline.json()['pipelineId']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline creation using AWS S3 - option 2\n",
    "Once the secret (aws-s3-secret) is created, we can now configure the document grounding pipeline using AWS S3 as the data source. This example shows how to set up a pipeline by referencing the created secret. The pipeline will extract and prepare documents from the specified S3 bucket for grounding.\n",
    "\n",
    "üîÑ You can follow a similar flow for SharePoint or other supported sources ‚Äî choosing between SharePoint and S3 is flexible based on your document storage setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_payload = {\n",
    "    \"type\": \"S3\",\n",
    "    \"configuration\": {\n",
    "        \"destination\": \"<generic secret name>\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create pipeline\n",
    "response = requests.post(\n",
    "    f\"{AI_API_URL}/v2/lm/document-grounding/pipelines\",\n",
    "    headers=headers,\n",
    "    json=pipeline_payload\n",
    ")\n",
    "\n",
    "if response.status_code == 201:\n",
    "    pipeline_id = response.json().get(\"pipelineId\")\n",
    "    print(\"‚úÖ Pipeline Created Successfully!\")\n",
    "    print(\"Pipeline ID:\", pipeline_id)\n",
    "else:\n",
    "    print(\"‚ùå Pipeline creation failed:\", response.status_code, response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Up the Orchestration Service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our document grounding pipeline ready, we can configure the LLM Orchestration Service to process incoming user queries in context.\n",
    "\n",
    "We define a system message to describe the business scenario for the LLM ‚Äî in this case, a Facility Solutions Company offering property maintenance and support services. The prompt template includes placeholders for the user‚Äôs query and the grounded document context (retrieved from S3 or SharePoint), making the responses personalized and context-aware.\n",
    "\n",
    "üí° This setup ensures that the LLM generates accurate, domain-specific, and grounded responses using the extracted content from your enterprise documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from gen_ai_hub.proxy import get_proxy_client\n",
    "from gen_ai_hub.orchestration.models.config import OrchestrationConfig\n",
    "from gen_ai_hub.orchestration.models.document_grounding import (GroundingModule, DocumentGrounding, GroundingFilterSearch,\n",
    "                                                                DataRepositoryType, DocumentGroundingFilter)\n",
    "from gen_ai_hub.orchestration.models.llm import LLM\n",
    "from gen_ai_hub.orchestration.models.message import SystemMessage, UserMessage\n",
    "from gen_ai_hub.orchestration.models.template import Template, TemplateValue\n",
    "from gen_ai_hub.orchestration.service import OrchestrationService"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the Orchestration Service\n",
    "aicore_client = get_proxy_client().ai_core_client\n",
    "orchestration_service = OrchestrationService(api_url=orchestration_service_url)\n",
    "llm = LLM(\n",
    "    name=\"gpt-4o\",\n",
    "    parameters={\n",
    "        'temperature': 0.0,\n",
    "    }\n",
    ")\n",
    "template = Template(\n",
    "            messages=[\n",
    "                SystemMessage(\"\"\"Facility Solutions Company provides services to luxury residential complexes, apartments,\n",
    "                individual homes, and commercial properties such as office buildings, retail spaces, industrial facilities, and educational institutions.\n",
    "                Customers are encouraged to reach out with maintenance requests, service deficiencies, follow-ups, or any issues they need by email.\n",
    "                \"\"\"),\n",
    "                UserMessage(\"\"\"You are a helpful assistant for any queries for answering questions.\n",
    "                Answer the request by providing relevant answers that fit to the request.\n",
    "                Request: {{ ?user_query }}\n",
    "                Context:{{ ?grounding_response }}\n",
    "                \"\"\"),\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Document Grounding\n",
    "filters = [DocumentGroundingFilter(id=\"vector\",\n",
    "                                   data_repositories=[\"52********************fc2c\"],\n",
    "                                   search_config=GroundingFilterSearch(max_chunk_count=2),\n",
    "                                   data_repository_type=DataRepositoryType.VECTOR.value\n",
    "                                   )\n",
    "]\n",
    "\n",
    "grounding_config = GroundingModule(\n",
    "            type=\"document_grounding_service\",\n",
    "            config=DocumentGrounding(input_params=[\"user_query\"], output_param=\"grounding_response\", filters=filters)\n",
    "        )\n",
    "\n",
    "config = OrchestrationConfig(\n",
    "    template=template,\n",
    "    llm=llm,\n",
    "    grounding=grounding_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Step 3: Generate context-relevant answer for a user query\n",
    "   - We now invoke the orchestration service by providing a user query. The query is grounded against the document index, and the LLM uses the grounding result to generate an informed response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the context provided, there are two issues that could be considered complaints:\n",
      "\n",
      "1. **HVAC Noise Issue**: Robert Kim from Lakeview Corporate Offices has expressed a concern about a minor noise issue following the repair of their HVAC system. He is requesting a technician to look into this matter.\n",
      "\n",
      "2. **Pothole on Victoria Rd**: A concerned citizen has reported a pothole on 27-3 Victoria Rd, highlighting the potential inconvenience and danger it poses to pedestrians and drivers. The citizen is urging the public administration to address this issue urgently.\n",
      "\n",
      "Both of these can be considered complaints or requests for further action to resolve the issues mentioned.\n"
     ]
    }
   ],
   "source": [
    "response = orchestration_service.run(config=config,\n",
    "                            template_values=[\n",
    "                                TemplateValue(\"user_query\", \"Is there any complaint?\"),\n",
    "                            ])\n",
    "print(response.orchestration_result.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
